{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import hashlib\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "DEEPSEEK_API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "cache = {}  # Global cache\n",
    "\n",
    "def display_cache_history(cache):\n",
    "    \"\"\"\n",
    "    Display the conversation history stored in the cache.\n",
    "    \n",
    "    Parameters:\n",
    "        cache (dict): The cache containing conversation history.\n",
    "    \"\"\"\n",
    "    for cache_key, response in cache.items():\n",
    "        print(f\"Cache Key: {cache_key}\")\n",
    "        print(\"Messages:\")\n",
    "        \n",
    "        # Extract messages from the nested response structure\n",
    "        if hasattr(response, 'choices'):\n",
    "            for choice in response.choices:\n",
    "                if hasattr(choice, 'message') and hasattr(choice.message, 'content'):\n",
    "                    print(f\"  {choice.message.role.capitalize()}: {choice.message.content}\")\n",
    "        \n",
    "        print(\"-\" * 40)  # Separator for readability\n",
    "\n",
    "def DeepseekV3(user_message, messages=None, reset_conversation=False, show_cache=False):\n",
    "    \"\"\"\n",
    "    Function to interact with the DeepSeek API in a conversational manner with caching.\n",
    "    \n",
    "    Parameters:\n",
    "        user_message (str): The message to send to the assistant.\n",
    "        messages (list, optional): The conversation history. Defaults to None.\n",
    "        reset_conversation (bool, optional): If True, starts a new conversation. Defaults to False.\n",
    "        show_cache (bool, optional): If True, displays the cache history before the response. Defaults to False.\n",
    "        \n",
    "    Returns:\n",
    "        list: The updated conversation history including the assistant's response.\n",
    "    \"\"\"\n",
    "    if reset_conversation or messages is None:\n",
    "        # Start a new conversation with a system message\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ]\n",
    "    else:\n",
    "        # Append the user's message to the existing conversation\n",
    "        messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "    \n",
    "    # Create a unique key for the cache\n",
    "    cache_key = hashlib.md5(json.dumps(messages, sort_keys=True).encode()).hexdigest()\n",
    "    \n",
    "    # Check if the response is in the cache\n",
    "    if cache_key in cache:\n",
    "        print(\"Using cached response.\")\n",
    "        response = cache[cache_key]\n",
    "    else:\n",
    "        print(\"Making API call.\")\n",
    "        # Send the API request\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=messages\n",
    "        )\n",
    "        # Store the response in the cache\n",
    "        cache[cache_key] = response\n",
    "    \n",
    "    # Display the cache history if requested\n",
    "    if show_cache:\n",
    "        print(\"\\nCache History:\")\n",
    "        display_cache_history(cache)\n",
    "    \n",
    "    # Get the assistant's response content\n",
    "    assistant_response = response.choices[0].message.content\n",
    "    \n",
    "    # Append the assistant's response to the conversation history\n",
    "    messages.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "    \n",
    "    # Print the assistant's response\n",
    "    print(f\"\\nAssistant Response:\\n{assistant_response}\")\n",
    "    \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making API call.\n",
      "\n",
      "Cache History:\n",
      "Cache Key: 063e44b8951c6263e81ac002d0a669d8\n",
      "Messages:\n",
      "  Assistant: Mao Zedong, the founding father of the People's Republic of China, is a highly controversial figure in history. While he is celebrated for his role in unifying China and ending decades of foreign domination and civil war, his leadership is also associated with significant failures and atrocities. Here are some of the most widely criticized aspects of Mao's rule:\n",
      "\n",
      "### 1. **The Great Leap Forward (1958‚Äì1962)**\n",
      "   - **Policy Failures**: Mao's campaign to rapidly industrialize China and collectivize agriculture led to economic disaster. Poor planning, unrealistic targets, and forced implementation caused widespread famine.\n",
      "   - **Human Cost**: An estimated **20 to 45 million people** died due to starvation, disease, and overwork during this period, making it one of the deadliest man-made disasters in history.\n",
      "\n",
      "### 2. **The Cultural Revolution (1966‚Äì1976)**\n",
      "   - **Social Chaos**: Mao launched this movement to purge \"bourgeois\" elements and consolidate his power. It led to widespread persecution of intellectuals, professionals, and perceived political enemies.\n",
      "   - **Violence and Destruction**: Millions were subjected to public humiliation, torture, and execution. Cultural heritage, including historical artifacts and literature, was destroyed.\n",
      "   - **Economic and Educational Disruption**: Schools and universities were shut down, and the economy suffered as a result of the chaos.\n",
      "\n",
      "### 3. **Political Repression**\n",
      "   - **Authoritarian Rule**: Mao maintained absolute power and suppressed dissent. Political opponents, real or imagined, were often imprisoned, tortured, or executed.\n",
      "   - **Mass Campaigns**: Campaigns like the **Anti-Rightist Movement** (1957) targeted intellectuals and critics, leading to the persecution of hundreds of thousands.\n",
      "\n",
      "### 4. **Economic Mismanagement**\n",
      "   - Mao's policies often prioritized ideology over practical economic considerations, leading to inefficiency, stagnation, and poverty for much of the population.\n",
      "\n",
      "### 5. **Environmental Damage**\n",
      "   - The Great Leap Forward included initiatives like the **Four Pests Campaign**, which targeted sparrows, among other animals. The elimination of sparrows disrupted ecosystems and contributed to crop failures and famine.\n",
      "\n",
      "### 6. **Legacy of Fear and Trauma**\n",
      "   - Mao's rule left a legacy of fear and trauma in Chinese society. Many families were torn apart, and the psychological scars of the Cultural Revolution persist to this day.\n",
      "\n",
      "### 7. **Misguided Ideology**\n",
      "   - Mao's adherence to Marxist-Leninist principles often led to policies that ignored China's unique social and economic conditions, resulting in widespread suffering.\n",
      "\n",
      "### 8. **Failure to Transition to Stable Governance**\n",
      "   - Mao's focus on perpetual revolution and class struggle prevented the establishment of stable governance structures, leaving China in a state of turmoil for much of his rule.\n",
      "\n",
      "### Conclusion\n",
      "While Mao is credited with unifying China and laying the foundation for its modern state, his policies caused immense suffering and set back China's development for decades. His legacy remains deeply polarizing, with some viewing him as a revolutionary hero and others as a tyrant responsible for catastrophic failures.\n",
      "----------------------------------------\n",
      "\n",
      "Assistant Response:\n",
      "Mao Zedong, the founding father of the People's Republic of China, is a highly controversial figure in history. While he is celebrated for his role in unifying China and ending decades of foreign domination and civil war, his leadership is also associated with significant failures and atrocities. Here are some of the most widely criticized aspects of Mao's rule:\n",
      "\n",
      "### 1. **The Great Leap Forward (1958‚Äì1962)**\n",
      "   - **Policy Failures**: Mao's campaign to rapidly industrialize China and collectivize agriculture led to economic disaster. Poor planning, unrealistic targets, and forced implementation caused widespread famine.\n",
      "   - **Human Cost**: An estimated **20 to 45 million people** died due to starvation, disease, and overwork during this period, making it one of the deadliest man-made disasters in history.\n",
      "\n",
      "### 2. **The Cultural Revolution (1966‚Äì1976)**\n",
      "   - **Social Chaos**: Mao launched this movement to purge \"bourgeois\" elements and consolidate his power. It led to widespread persecution of intellectuals, professionals, and perceived political enemies.\n",
      "   - **Violence and Destruction**: Millions were subjected to public humiliation, torture, and execution. Cultural heritage, including historical artifacts and literature, was destroyed.\n",
      "   - **Economic and Educational Disruption**: Schools and universities were shut down, and the economy suffered as a result of the chaos.\n",
      "\n",
      "### 3. **Political Repression**\n",
      "   - **Authoritarian Rule**: Mao maintained absolute power and suppressed dissent. Political opponents, real or imagined, were often imprisoned, tortured, or executed.\n",
      "   - **Mass Campaigns**: Campaigns like the **Anti-Rightist Movement** (1957) targeted intellectuals and critics, leading to the persecution of hundreds of thousands.\n",
      "\n",
      "### 4. **Economic Mismanagement**\n",
      "   - Mao's policies often prioritized ideology over practical economic considerations, leading to inefficiency, stagnation, and poverty for much of the population.\n",
      "\n",
      "### 5. **Environmental Damage**\n",
      "   - The Great Leap Forward included initiatives like the **Four Pests Campaign**, which targeted sparrows, among other animals. The elimination of sparrows disrupted ecosystems and contributed to crop failures and famine.\n",
      "\n",
      "### 6. **Legacy of Fear and Trauma**\n",
      "   - Mao's rule left a legacy of fear and trauma in Chinese society. Many families were torn apart, and the psychological scars of the Cultural Revolution persist to this day.\n",
      "\n",
      "### 7. **Misguided Ideology**\n",
      "   - Mao's adherence to Marxist-Leninist principles often led to policies that ignored China's unique social and economic conditions, resulting in widespread suffering.\n",
      "\n",
      "### 8. **Failure to Transition to Stable Governance**\n",
      "   - Mao's focus on perpetual revolution and class struggle prevented the establishment of stable governance structures, leaving China in a state of turmoil for much of his rule.\n",
      "\n",
      "### Conclusion\n",
      "While Mao is credited with unifying China and laying the foundation for its modern state, his policies caused immense suffering and set back China's development for decades. His legacy remains deeply polarizing, with some viewing him as a revolutionary hero and others as a tyrant responsible for catastrophic failures.\n"
     ]
    }
   ],
   "source": [
    "# Start a new conversation and display the cache\n",
    "messages = DeepseekV3(\"What did Mao Zedong do wrong\", reset_conversation=True, show_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making API call.\n",
      "\n",
      "Assistant Response:\n",
      "It‚Äôs tough out there, but don‚Äôt lose hope! Here are some actionable steps to navigate the oversaturated job market and build your career, even without experience:\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **Expand Your Skill Set**\n",
      "   - **Learn In-Demand Tools**: If you‚Äôre in Data Science or Data Engineering, focus on tools like Snowflake, Databricks, Apache Airflow, or cloud platforms (AWS, GCP, Azure).  \n",
      "   - **Add SWE Skills**: Learn Python, Java, or Go for backend development, or pick up frontend skills (React, JavaScript) to diversify your profile.  \n",
      "   - **Certifications**: Get certified in cloud platforms, data engineering, or machine learning (e.g., AWS Certified Data Analytics, Google Cloud Data Engineer).\n",
      "\n",
      "---\n",
      "\n",
      "### 2. **Build a Portfolio**\n",
      "   - **Personal Projects**: Work on real-world projects (e.g., building a data pipeline, creating a dashboard, or deploying a machine learning model).  \n",
      "   - **Open Source Contributions**: Contribute to open-source projects on GitHub. It‚Äôs a great way to showcase your skills and collaborate with others.  \n",
      "   - **Kaggle Competitions**: Participate in Kaggle to demonstrate your data science and machine learning expertise.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. **Network Strategically**\n",
      "   - **LinkedIn**: Connect with professionals in your field, join relevant groups, and engage with posts.  \n",
      "   - **Meetups and Conferences**: Attend industry events (virtual or in-person) to meet people and learn about opportunities.  \n",
      "   - **Informational Interviews**: Reach out to people in roles you‚Äôre interested in and ask for advice or insights.\n",
      "\n",
      "---\n",
      "\n",
      "### 4. **Consider Alternative Roles**\n",
      "   - **Data Analyst**: A stepping stone to Data Science or Data Engineering.  \n",
      "   - **Business Intelligence (BI)**: Focus on visualization tools like Tableau or Power BI.  \n",
      "   - **DevOps or Cloud Engineering**: If you‚Äôre interested in infrastructure, this could be a good pivot.  \n",
      "   - **Freelancing**: Platforms like Upwork or Fiverr can help you gain experience and build a client base.\n",
      "\n",
      "---\n",
      "\n",
      "### 5. **Internships and Volunteer Work**\n",
      "   - **Internships**: Even unpaid internships can provide valuable experience and connections.  \n",
      "   - **Volunteer**: Offer your skills to non-profits or small businesses to build your resume.\n",
      "\n",
      "---\n",
      "\n",
      "### 6. **Tailor Your Resume and Applications**\n",
      "   - **Customize**: Tailor your resume and cover letter for each job application. Highlight relevant skills and projects.  \n",
      "   - **ATS Optimization**: Use keywords from the job description to pass Applicant Tracking Systems.\n",
      "\n",
      "---\n",
      "\n",
      "### 7. **Stay Persistent and Positive**\n",
      "   - **Rejections Are Normal**: Everyone faces rejection‚Äîit‚Äôs part of the process. Learn from feedback and keep improving.  \n",
      "   - **Upskill Continuously**: The tech industry evolves fast, so stay updated with trends and technologies.  \n",
      "   - **Mindset Matters**: Focus on progress, not perfection. Celebrate small wins along the way.\n",
      "\n",
      "---\n",
      "\n",
      "### 8. **Consider Further Education (If Feasible)**\n",
      "   - **Bootcamps**: Short, intensive programs can help you specialize in a specific area.  \n",
      "   - **Master‚Äôs Degree**: If you‚Äôre passionate about research or want to dive deeper, this could be an option.  \n",
      "\n",
      "---\n",
      "\n",
      "### 9. **Think Outside the Box**\n",
      "   - **Startups**: Smaller companies may be more willing to take a chance on someone without experience.  \n",
      "   - **Remote Jobs**: Look for remote opportunities globally‚Äîthey often have less competition.  \n",
      "   - **Create Your Own Job**: Build a blog, YouTube channel, or consultancy around your expertise.  \n",
      "\n",
      "---\n",
      "\n",
      "It‚Äôs a challenging time, but with persistence, adaptability, and a proactive approach, you‚Äôll find your way. Keep grinding‚Äîyou‚Äôve got this! üí™\n"
     ]
    }
   ],
   "source": [
    "# Continue the conversation without displaying the cache\n",
    "messages = DeepseekV3(\"Call me the unemp\", messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making API call.\n",
      "\n",
      "Assistant Response:\n",
      "Sure, here's a dark joke for you:\n",
      "\n",
      "\"Why did the unemployed Data Science grad bring a ladder to the job interview?  \n",
      "Because they heard the bar for entry-level positions was set *way too high*... and they‚Äôre still climbing to reach it.\"\n",
      "\n",
      "(Too real? üòÖ)\n"
     ]
    }
   ],
   "source": [
    "# Start another new conversation and display the cache\n",
    "messages = DeepseekV3(\"Make a dark joke about unemployed Data Science grads or data engineer grad\", reset_conversation=True, show_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "CODESTRAL_MAMBA_API_KEY = os.getenv(\"CODESTRAL_MAMBA_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Lu·∫≠t Gi√°o D·ª•c nh·∫±m ƒë·∫°t ƒë·∫øn m·ª•c ti√™u gi√°o d·ª•c n√†o trong s·ªë c√°c m·ª•c ti√™u sau ƒë√¢y?\n",
      "   a) Ph√°t tri·ªÉn to√†n di·ªán con ng∆∞·ªùi Vi·ªát Nam\n",
      "   b) N√¢ng cao d√¢n tr√≠, ph√°t tri·ªÉn ngu·ªìn nh√¢n l·ª±c\n",
      "   c) B·ªìi d∆∞·ª°ng nh√¢n t√†i, ƒë√°p ·ª©ng y√™u c·∫ßu c·ªßa s·ª± nghi·ªáp x√¢y d·ª±ng, b·∫£o v·ªá T·ªï qu·ªëc v√† h·ªôi nh·∫≠p qu·ªëc t·∫ø\n",
      "   d) Ph√°t huy ti·ªÅm nƒÉng, kh·∫£ nƒÉng s√°ng t·∫°o c·ªßa m·ªói c√° nh√¢n\n",
      "   e) C√≥ ph·∫©m ch·∫•t, nƒÉng l·ª±c v√† √Ω th·ª©c c√¥ng d√¢n; c√≥ l√≤ng y√™u n∆∞·ªõc, tinh th·∫ßn d√¢n t·ªôc, trung th√†nh v·ªõi l√Ω t∆∞·ªüng ƒë·ªôc l·∫≠p d√¢n t·ªôc v√† ch·ªß nghƒ©a x√£ h·ªôi\n",
      "\n",
      "2. Ch∆∞∆°ng I c·ªßa Lu·∫≠t Gi√°o D·ª•c n√≥i v·ªÅ m·ª•c ti√™u gi√°o d·ª•c chung n√†o trong c√°c m·ª•c ti√™u sau ƒë√¢y?\n",
      "   a) Ph√°t tri·ªÉn to√†n di·ªán con ng∆∞·ªùi Vi·ªát Nam\n",
      "   b) N√¢ng cao d√¢n tr√≠, ph√°t tri·ªÉn ngu·ªìn nh√¢n l·ª±c\n",
      "   c) B·ªìi d∆∞·ª°ng nh√¢n t√†i, ƒë√°p ·ª©ng y√™u c·∫ßu c·ªßa s·ª± nghi·ªáp x√¢y d·ª±ng, b·∫£o v·ªá T·ªï qu·ªëc v√† h·ªôi nh·∫≠p qu·ªëc t·∫ø\n",
      "   d) Ph√°t huy ti·ªÅm nƒÉng, kh·∫£ nƒÉng s√°ng t·∫°o c·ªßa m·ªói c√° nh√¢n\n",
      "   e) C√≥ ph·∫©m ch·∫•t, nƒÉng l·ª±c v√† √Ω th·ª©c c√¥ng d√¢n; c√≥ l√≤ng y√™u n∆∞·ªõc, tinh th·∫ßn d√¢n t·ªôc, trung th√†nh v·ªõi l√Ω t∆∞·ªüng ƒë·ªôc l·∫≠p d√¢n t·ªôc v√† ch·ªß nghƒ©a x√£ h·ªôi\n",
      "\n",
      "3. ƒêi·ªÅu 2 c·ªßa Lu·∫≠t Gi√°o D·ª•c n√≥i v·ªÅ m·ª•c ti√™u gi√°o d·ª•c v·ªÅ ph√°t tri·ªÉn con ng∆∞·ªùi Vi·ªát Nam. H√£y g·ª£i √Ω m·ªôt m·ª•c ti√™u ph√°t tri·ªÉn con ng∆∞·ªùi Vi·ªát Nam t·ª´ ƒêi·ªÅu 2.\n",
      "   a) Ph√°t tri·ªÉn to√†n di·ªán con ng∆∞·ªùi Vi·ªát Nam\n",
      "   b) N√¢ng cao d√¢n tr√≠, ph√°t tri·ªÉn ngu·ªìn nh√¢n l·ª±c\n",
      "   c) B·ªìi d∆∞·ª°ng nh√¢n t√†i, ƒë√°p ·ª©ng y√™u c·∫ßu c·ªßa s·ª± nghi·ªáp x√¢y d·ª±ng, b·∫£o v·ªá T·ªï qu·ªëc v√† h·ªôi nh·∫≠p qu·ªëc t·∫ø\n",
      "   d) Ph√°t huy ti·ªÅm nƒÉng, kh·∫£ nƒÉng s√°ng t·∫°o c·ªßa m·ªói c√° nh√¢n\n",
      "   e) C√≥ ph·∫©m ch·∫•t, nƒÉng l·ª±c v√† √Ω th·ª©c c√¥ng d√¢n; c√≥ l√≤ng y√™u n∆∞·ªõc, tinh th·∫ßn d√¢n t·ªôc, trung th√†nh v·ªõi l√Ω t∆∞·ªüng ƒë·ªôc l·∫≠p d√¢n t·ªôc v√† ch·ªß nghƒ©a x√£ h·ªôi\n",
      "\n",
      "4. Lu·∫≠t Gi√°o D·ª•c ƒë·∫∑t ra m·ª•c ti√™u n√¢ng cao d√¢n tr√≠, ph√°t tri·ªÉn ngu·ªìn nh√¢n l·ª±c. T·ª´ ƒë√¢u m√† Lu·∫≠t Gi√°o D·ª•c n√≥i ƒë·∫øn ngu·ªìn nh√¢n l·ª±c?\n",
      "   a) Ph√°t tri·ªÉn to√†n di·ªán con ng∆∞·ªùi Vi·ªát Nam\n",
      "   b) N√¢ng cao d√¢n tr√≠, ph√°t tri·ªÉn ngu·ªìn nh√¢n l·ª±c\n",
      "   c) B·ªìi d∆∞·ª°ng nh√¢n t√†i, ƒë√°p ·ª©ng y√™u c·∫ßu c·ªßa s·ª± nghi·ªáp x√¢y d·ª±ng, b·∫£o v·ªá T·ªï qu·ªëc v√† h·ªôi nh·∫≠p qu·ªëc t·∫ø\n",
      "   d) Ph√°t huy ti·ªÅm nƒÉng, kh·∫£ nƒÉng s√°ng t·∫°o c·ªßa m·ªói c√° nh√¢n\n",
      "   e) C√≥ ph·∫©m ch·∫•t, nƒÉng l·ª±c v√† √Ω th·ª©c c√¥ng d√¢n; c√≥ l√≤ng y√™u n∆∞·ªõc, tinh th·∫ßn d√¢n t·ªôc, trung th√†nh v·ªõi l√Ω t∆∞·ªüng ƒë·ªôc l·∫≠p d√¢n t·ªôc v√† ch·ªß nghƒ©a x√£ h·ªôi\n",
      "\n",
      "5. M·ª•c ti√™u gi√°o d·ª•c n√†o trong Lu·∫≠t Gi√°o D·ª•c n√≥i v·ªÅ c√¥ng d√¢n v√† danh t·ªôc, nh√† n∆∞·ªõc v√† x√£ h·ªôi?\n",
      "   a) Ph√°t tri·ªÉn to√†n di·ªán con ng∆∞·ªùi Vi·ªát Nam\n",
      "   b) N√¢ng cao d√¢n tr√≠, ph√°t tri·ªÉn ngu·ªìn nh√¢n l·ª±c\n",
      "   c) B·ªìi d∆∞·ª°ng nh√¢n t√†i, ƒë√°p ·ª©ng y√™u c·∫ßu c·ªßa s·ª± nghi·ªáp x√¢y d·ª±ng, b·∫£o v·ªá T·ªï qu·ªëc v√† h·ªôi nh·∫≠p qu·ªëc t·∫ø\n",
      "   d) Ph√°t huy ti·ªÅm nƒÉng, kh·∫£ nƒÉng s√°ng t·∫°o c·ªßa m·ªói c√° nh√¢n\n",
      "   e) C√≥ ph·∫©m ch·∫•t, nƒÉng l·ª±c v√† √Ω th·ª©c c√¥ng d√¢n; c√≥ l√≤ng y√™u n∆∞·ªõc, tinh th·∫ßn d√¢n t·ªôc, trung th√†nh v·ªõi l√Ω t∆∞·ªüng ƒë·ªôc l·∫≠p d√¢n t·ªôc v√† ch·ªß nghƒ©a x√£ h·ªôi\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from mistralai import Mistral, UserMessage\n",
    "\n",
    "# Replace with your actual API key\n",
    "model = \"codestral-mamba-latest\"\n",
    "\n",
    "client = Mistral(api_key=CODESTRAL_MAMBA_API_KEY)\n",
    "\n",
    "def chat_mistral(prompt: str):\n",
    "    messages = [\n",
    "        UserMessage(content=prompt)\n",
    "    ]\n",
    "\n",
    "    # No streaming\n",
    "    chat_response = client.chat.complete(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "    return chat_response.choices[0].message.content\n",
    "\n",
    "# Example usage\n",
    "prompt = \"\"\"t·∫°o 5 c√¢u h·ªèi t·ª´ b·ªô lu·∫≠t n√†y v√† d√πng ti·∫øng vi·ªát. DO NOT WRITE IN ENGLISH ONLY VIETNAMESE;\n",
    "        \"law_title\": \"Lu·∫≠t Gi√°o D·ª•c\",\n",
    "        \"law_number\": \"Lu·∫≠t s·ªë: 43/2019/QH14\",\n",
    "        \"chapter_title\": \"Ch∆∞∆°ng I\",\n",
    "        \"article_number\": \"ƒêi·ªÅu 2\",\n",
    "        \"title\": \"M·ª•c ti√™u gi√°o d·ª•c\",\n",
    "        \"content\": \"M·ª•c ti√™u gi√°o d·ª•c nh·∫±m ph√°t tri·ªÉn to√†n di·ªán con ng∆∞·ªùi Vi·ªát Nam c√≥ ƒë·∫°o ƒë·ª©c, tri th·ª©c, vƒÉn h√≥a, s·ª©c kh·ªèe, th·∫©m m·ªπ v√† ngh·ªÅ nghi·ªáp; c√≥ ph·∫©m ch·∫•t, nƒÉng l·ª±c v√† √Ω th·ª©c c√¥ng d√¢n; c√≥ l√≤ng y√™u n∆∞·ªõc, tinh th·∫ßn d√¢n t·ªôc, trung th√†nh v·ªõi l√Ω t∆∞·ªüng ƒë·ªôc l·∫≠p d√¢n t·ªôc v√† ch·ªß nghƒ©a x√£ h·ªôi; ph√°t huy ti·ªÅm nƒÉng, kh·∫£ nƒÉng s√°ng t·∫°o c·ªßa m·ªói c√° nh√¢n; n√¢ng cao d√¢n tr√≠, ph√°t tri·ªÉn ngu·ªìn nh√¢n l·ª±c, b·ªìi d∆∞·ª°ng nh√¢n t√†i, ƒë√°p ·ª©ng y√™u c·∫ßu c·ªßa s·ª± nghi·ªáp x√¢y d·ª±ng, b·∫£o v·ªá T·ªï qu·ªëc v√† h·ªôi nh·∫≠p qu·ªëc t·∫ø. \",\n",
    "        \"id\": \"82b52978\"\n",
    "    },\n",
    "\"\"\"\n",
    "response = chat_mistral(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models: object='list' data=[BaseModelCard(id='ministral-3b-2410', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False), object='model', created=1735796383, owned_by='mistralai', name='ministral-3b-2410', description='Official ministral-3b-2410 Mistral AI model', max_context_length=131072, aliases=['ministral-3b-latest'], deprecation=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='ministral-3b-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False), object='model', created=1735796383, owned_by='mistralai', name='ministral-3b-2410', description='Official ministral-3b-2410 Mistral AI model', max_context_length=131072, aliases=['ministral-3b-2410'], deprecation=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='ministral-8b-2410', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False), object='model', created=1735796383, owned_by='mistralai', name='ministral-8b-2410', description='Official ministral-8b-2410 Mistral AI model', max_context_length=131072, aliases=['ministral-8b-latest'], deprecation=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='ministral-8b-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False), object='model', created=1735796383, owned_by='mistralai', name='ministral-8b-2410', description='Official ministral-8b-2410 Mistral AI model', max_context_length=131072, aliases=['ministral-8b-2410'], deprecation=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='open-mistral-7b', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False), object='model', created=1735796383, owned_by='mistralai', name='open-mistral-7b', description='Official open-mistral-7b Mistral AI model', max_context_length=32768, aliases=['mistral-tiny', 'mistral-tiny-2312'], deprecation=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='mistral-tiny', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False), object='model', created=1735796383, owned_by='mistralai', name='open-mistral-7b', description='Official open-mistral-7b Mistral AI model', max_context_length=32768, aliases=['open-mistral-7b', 'mistral-tiny-2312'], deprecation=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='mistral-tiny-2312', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False), object='model', created=1735796383, owned_by='mistralai', name='open-mistral-7b', description='Official open-mistral-7b Mistral AI model', max_context_length=32768, aliases=['open-mistral-7b', 'mistral-tiny'], deprecation=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='open-mistral-nemo', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False), object='model', created=1735796383, owned_by='mistralai', name='open-mistral-nemo', description='Official open-mistral-nemo Mistral AI model', max_context_length=131072, aliases=['open-mistral-nemo-2407', 'mistral-tiny-2407', 'mistral-tiny-latest'], deprecation=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='open-mistral-nemo-2407', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False), object='model', created=1735796383, owned_by='mistralai', name='open-mistral-nemo', description='Official open-mistral-nemo Mistral AI model', max_context_length=131072, aliases=['open-mistral-nemo', 'mistral-tiny-2407', 'mistral-tiny-latest'], deprecation=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='mistral-tiny-2407', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False), object='model', created=1735796383, owned_by='mistralai', name='open-mistral-nemo', description='Official open-mistral-nemo Mistral AI model', max_context_length=131072, aliases=['open-mistral-nemo', 'open-mistral-nemo-2407', 'mistral-tiny-latest'], deprecation=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='mistral-tiny-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False), object='model', created=1735796383, owned_by='mistralai', name='open-mistral-nemo', description='Official open-mistral-nemo Mistral AI model', max_context_length=131072, aliases=['open-mistral-nemo', 'open-mistral-nemo-2407', 'mistral-tiny-2407'], deprecation=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='open-mixtral-8x7b', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False), object='model', created=1735796383, owned_by='mistralai', name='open-mixtral-8x7b', description='Official open-mixtral-8x7b Mistral AI model', max_context_length=32768, aliases=['mistral-small', 'mistral-small-2312'], deprecation=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='mistral-small', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False), object='model', created=1735796383, owned_by='mistralai', name='open-mixtral-8x7b', description='Official open-mixtral-8x7b Mistral AI model', max_context_length=32768, aliases=['open-mixtral-8x7b', 'mistral-small-2312'], deprecation=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='mistral-small-2312', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False), object='model', created=1735796383, owned_by='mistralai', name='open-mixtral-8x7b', description='Official open-mixtral-8x7b Mistral AI model', max_context_length=32768, aliases=['open-mixtral-8x7b', 'mistral-small'], deprecation=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='open-mixtral-8x22b', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False), object='model', created=1735796383, owned_by='mistralai', name='open-mixtral-8x22b', description='Official open-mixtral-8x22b Mistral AI model', max_context_length=65536, aliases=['open-mixtral-8x22b-2404'], deprecation=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='open-mixtral-8x22b-2404', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False), object='model', created=1735796383, owned_by='mistralai', name='open-mixtral-8x22b', description='Official open-mixtral-8x22b Mistral AI model', max_context_length=65536, aliases=['open-mixtral-8x22b'], deprecation=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='mistral-small-2402', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False), object='model', created=1735796383, owned_by='mistralai', name='mistral-small-2402', description='Official mistral-small-2402 Mistral AI model', max_context_length=32768, aliases=[], deprecation=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='mistral-small-2409', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False), object='model', created=1735796383, owned_by='mistralai', name='mistral-small-2409', description='Official mistral-small-2409 Mistral AI model', max_context_length=32768, aliases=['mistral-small-latest'], deprecation=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='mistral-small-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False), object='model', created=1735796383, owned_by='mistralai', name='mistral-small-2409', description='Official mistral-small-2409 Mistral AI model', max_context_length=32768, aliases=['mistral-small-2409'], deprecation=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='mistral-medium-2312', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False), object='model', created=1735796383, owned_by='mistralai', name='mistral-medium-2312', description='Official mistral-medium-2312 Mistral AI model', max_context_length=32768, aliases=['mistral-medium', 'mistral-medium-latest'], deprecation=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='mistral-medium', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False), object='model', created=1735796383, owned_by='mistralai', name='mistral-medium-2312', description='Official mistral-medium-2312 Mistral AI model', max_context_length=32768, aliases=['mistral-medium-2312', 'mistral-medium-latest'], deprecation=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='mistral-medium-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False), object='model', created=1735796383, owned_by='mistralai', name='mistral-medium-2312', description='Official mistral-medium-2312 Mistral AI model', max_context_length=32768, aliases=['mistral-medium-2312', 'mistral-medium'], deprecation=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='mistral-large-2402', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False), object='model', created=1735796383, owned_by='mistralai', name='mistral-large-2402', description='Official mistral-large-2402 Mistral AI model', max_context_length=32768, aliases=[], deprecation=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='mistral-large-2407', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False), object='model', created=1735796383, owned_by='mistralai', name='mistral-large-2407', description='Official mistral-large-2407 Mistral AI model', max_context_length=131072, aliases=[], deprecation=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='mistral-large-2411', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False), object='model', created=1735796383, owned_by='mistralai', name='mistral-large-2411', description='Official mistral-large-2411 Mistral AI model', max_context_length=131072, aliases=['mistral-large-latest'], deprecation=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='mistral-large-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False), object='model', created=1735796383, owned_by='mistralai', name='mistral-large-2411', description='Official mistral-large-2411 Mistral AI model', max_context_length=131072, aliases=['mistral-large-2411'], deprecation=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='pixtral-large-2411', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=True), object='model', created=1735796383, owned_by='mistralai', name='pixtral-large-2411', description='Official pixtral-large-2411 Mistral AI model', max_context_length=131072, aliases=['pixtral-large-latest'], deprecation=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='pixtral-large-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=True), object='model', created=1735796383, owned_by='mistralai', name='pixtral-large-2411', description='Official pixtral-large-2411 Mistral AI model', max_context_length=131072, aliases=['pixtral-large-2411'], deprecation=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='codestral-2405', capabilities=ModelCapabilities(completion_chat=True, completion_fim=True, function_calling=True, fine_tuning=True, vision=False), object='model', created=1735796383, owned_by='mistralai', name='codestral-2405', description='Official codestral-2405 Mistral AI model', max_context_length=32768, aliases=['codestral-latest'], deprecation=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='codestral-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=True, function_calling=True, fine_tuning=True, vision=False), object='model', created=1735796383, owned_by='mistralai', name='codestral-2405', description='Official codestral-2405 Mistral AI model', max_context_length=32768, aliases=['codestral-2405'], deprecation=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='codestral-mamba-2407', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False), object='model', created=1735796383, owned_by='mistralai', name='codestral-mamba-2407', description='Official codestral-mamba-2407 Mistral AI model', max_context_length=262144, aliases=['open-codestral-mamba', 'codestral-mamba-latest'], deprecation=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='open-codestral-mamba', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False), object='model', created=1735796383, owned_by='mistralai', name='codestral-mamba-2407', description='Official codestral-mamba-2407 Mistral AI model', max_context_length=262144, aliases=['codestral-mamba-2407', 'codestral-mamba-latest'], deprecation=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='codestral-mamba-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False), object='model', created=1735796383, owned_by='mistralai', name='codestral-mamba-2407', description='Official codestral-mamba-2407 Mistral AI model', max_context_length=262144, aliases=['codestral-mamba-2407', 'open-codestral-mamba'], deprecation=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='pixtral-12b-2409', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=True), object='model', created=1735796383, owned_by='mistralai', name='pixtral-12b-2409', description='Official pixtral-12b-2409 Mistral AI model', max_context_length=131072, aliases=['pixtral-12b', 'pixtral-12b-latest'], deprecation=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='pixtral-12b', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=True), object='model', created=1735796383, owned_by='mistralai', name='pixtral-12b-2409', description='Official pixtral-12b-2409 Mistral AI model', max_context_length=131072, aliases=['pixtral-12b-2409', 'pixtral-12b-latest'], deprecation=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='pixtral-12b-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=True), object='model', created=1735796383, owned_by='mistralai', name='pixtral-12b-2409', description='Official pixtral-12b-2409 Mistral AI model', max_context_length=131072, aliases=['pixtral-12b-2409', 'pixtral-12b'], deprecation=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='mistral-embed', capabilities=ModelCapabilities(completion_chat=False, completion_fim=False, function_calling=False, fine_tuning=False, vision=False), object='model', created=1735796383, owned_by='mistralai', name='mistral-embed', description='Official mistral-embed Mistral AI model', max_context_length=32768, aliases=[], deprecation=None, default_model_temperature=None, TYPE='base'), BaseModelCard(id='mistral-moderation-2411', capabilities=ModelCapabilities(completion_chat=False, completion_fim=False, function_calling=False, fine_tuning=False, vision=False), object='model', created=1735796383, owned_by='mistralai', name='mistral-moderation-2411', description='Official mistral-moderation-2411 Mistral AI model', max_context_length=32768, aliases=['mistral-moderation-latest'], deprecation=None, default_model_temperature=None, TYPE='base'), BaseModelCard(id='mistral-moderation-latest', capabilities=ModelCapabilities(completion_chat=False, completion_fim=False, function_calling=False, fine_tuning=False, vision=False), object='model', created=1735796383, owned_by='mistralai', name='mistral-moderation-2411', description='Official mistral-moderation-2411 Mistral AI model', max_context_length=32768, aliases=['mistral-moderation-2411'], deprecation=None, default_model_temperature=None, TYPE='base')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from mistralai import Mistral\n",
    "\n",
    "# Replace with your actual API key\n",
    "CODESTRAL_MAMBA_API_KEY = CODESTRAL_MAMBA_API_KEY\n",
    "\n",
    "client = Mistral(api_key=CODESTRAL_MAMBA_API_KEY)\n",
    "\n",
    "# List available models\n",
    "models = client.models.list()\n",
    "print(\"Available models:\", models)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_aider",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
